# %## =========================================
# Week 2 â€” Simple Nonlinear Node (Single Hidden Layer, 2 Hidden Nodes)
#  - Inputs: Height, Weight (normalized to 0~1)
#  - Hidden nodes: h1(x1) = -x1 + 1, h2(x2) = x2
#  - Output: Score = a1*h1 + a2*h2  (a1,a2 â‰¥ 0, a1+a2=1), Label via threshold T
#  - Format aligned with Week 1 script style
# =========================================

#%% Imports & Paths
import os, re
import numpy as np
import pandas as pd

# ê¸°ë³¸ ë°ì´í„° ê²½ë¡œ ì„¤ì • (ë™ì¼ í´ë” ìš°ì„  â†’ /mnt/data í´ë°±)
CANDIDATES = [
    os.path.join(os.getcwd(), "week1_health_dataset.csv"),
    "/mnt/data/week1_health_dataset.csv"
]
CSV_PATH = next((p for p in CANDIDATES if os.path.exists(p)), None)
assert CSV_PATH is not None, "âŒ ë°ì´í„° íŒŒì¼ week1_health_dataset.csv ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

OUT_DIR  = os.path.join(os.path.dirname(CSV_PATH), "outputs_week2")
os.makedirs(OUT_DIR, exist_ok=True)

print("CSV_PATH:", CSV_PATH)
print("OUT_DIR :", OUT_DIR)

# %## Load Dataset & Normalize Headers (snake_case)
df = pd.read_csv(CSV_PATH)

def to_snake(name: str) -> str:
    name = name.strip()
    name = re.sub(r'[\s/()\-\u200b]+', '_', name)
    name = re.sub(r'__+', '_', name)
    return name.strip('_').lower()

df.columns = [to_snake(c) for c in df.columns]
print("âœ… Columns:", list(df.columns))
#%%
# ì´ë²ˆ ì£¼ëŠ” Height/Weightë§Œ ì‚¬ìš©
needed = {'id','height_in','weight_lb'}
missing = needed - set(df.columns)
assert not missing, f"âŒ ëˆ„ë½ ì»¬ëŸ¼: {missing}. CSV í—¤ë” í™•ì¸ í•„ìš”."

# %## Train/Test Split (Week 1ê³¼ ë™ì¼ ê·œì¹™: 1â€“10 train, 11â€“12 test)
train_mask = df['id'].between(1, 10)
test_mask  = df['id'].between(11, 12)

train = df.loc[train_mask].copy()
test  = df.loc[test_mask].copy()

print(f"Train size: {len(train)}  | Test size: {len(test)}")
#%%
# Minâ€“Max Normalization (fit on train only)
def minmax_fit(series: pd.Series):
    lo, hi = float(series.min()), float(series.max())
    return lo, hi

def minmax_transform(series: pd.Series, lo: float, hi: float):
    return (series - lo) / (hi - lo) if hi > lo else pd.Series(0.0, index=series.index)

h_lo, h_hi = minmax_fit(train['height_in'])
w_lo, w_hi = minmax_fit(train['weight_lb'])

train['height_norm'] = minmax_transform(train['height_in'], h_lo, h_hi)
train['weight_norm'] = minmax_transform(train['weight_lb'], w_lo, w_hi)

# testëŠ” trainì˜ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜
test['height_norm'] = minmax_transform(test['height_in'], h_lo, h_hi)
test['weight_norm'] = minmax_transform(test['weight_lb'], w_lo, w_hi)

# 0~1 ë²”ìœ„ ì²´í¬(ì •ë³´ìš©)
for nm in ['height_norm','weight_norm']:
    lo, hi = float(train[nm].min()), float(train[nm].max())
    print(f"{nm}: train range ~ [{lo:.3f}, {hi:.3f}]")

#%% Define Hidden Nodes (Nonlinear Design)
# Node_11: h1(x1) = -x1 + 1 (í‚¤ê°€ ì»¤ì§ˆìˆ˜ë¡ ê°ì†Œ â†’ ë¶„ëª¨ íš¨ê³¼)
# Node_21: h2(x2) =  x2     (ëª¸ë¬´ê²Œê°€ í´ìˆ˜ë¡ ì¦ê°€ â†’ ë¶„ì íš¨ê³¼)
def h1_height(x1: pd.Series) -> pd.Series:
    return -x1 + 1.0

def h2_weight(x2: pd.Series) -> pd.Series:
    return x2

# %## Output Score = a1*h1 + a2*h2  (a1+a2=1)
# ê¸°ë³¸ ê°€ì¤‘ì¹˜ (í•„ìš” ì‹œ ë³€ê²½)
a1, a2 = 0.5, 0.5
assert abs((a1 + a2) - 1.0) < 1e-9, "a1+a2=1 ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
T = 0.50  # ê¸°ë³¸ ì„ê³„ê°’ (í•„ìš” ì‹œ ë³€ê²½)

print(f"Weights (a1,a2) = ({a1:.2f}, {a2:.2f}) | Threshold T = {T:.2f}")

#%% Compute Score & Predict (Train/Test)
def compute_score(df_part: pd.DataFrame, a1: float, a2: float) -> pd.Series:
    x1 = df_part['height_norm']
    x2 = df_part['weight_norm']
    z  = a1 * h1_height(x1) + a2 * h2_weight(x2)
    return z

def predict_label(score: pd.Series, T: float) -> pd.Series:
    return np.where(score < T, 'Healthy', 'Unhealthy')

train['score_week2'] = compute_score(train, a1, a2)
train['pred_label']  = predict_label(train['score_week2'], T)

test['score_week2'] = compute_score(test, a1, a2)
test['pred_label']  = predict_label(test['score_week2'], T)

print("âœ… Score & Prediction ì™„ë£Œ")

# %## Save Outputs
out_train_csv = os.path.join(OUT_DIR, "week2_train_predictions.csv")
out_test_csv  = os.path.join(OUT_DIR, "week2_test_predictions.csv")
train[['id','height_in','weight_lb','height_norm','weight_norm','score_week2','pred_label']].to_csv(out_train_csv, index=False)
test[['id','height_in','weight_lb','height_norm','weight_norm','score_week2','pred_label']].to_csv(out_test_csv, index=False)

print("ğŸ’¾ Saved:", out_train_csv)
print("ğŸ’¾ Saved:", out_test_csv)

#%% (Optional) Grid Search for (a1,a2,T)
#  - a1 âˆˆ {0.0, 0.1, â€¦, 1.0}, a2 = 1 - a1
#  - T âˆˆ {0.30, 0.35, â€¦, 0.70}
#  - ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” true_label ì´ í•„ìš” (Week 1 ì œì¶œ í›„ ê³µê°œ ê°€ì •)
#  - ì—¬ê¸°ì„œëŠ” true_label ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ë™ì‘í•˜ë„ë¡ êµ¬í˜„ (ì—†ìœ¼ë©´ ìŠ¤í‚µ)
if 'true_label' in train.columns:
    grid_a1 = np.round(np.linspace(0.0, 1.0, 11), 2)
    grid_T  = np.round(np.linspace(0.30, 0.70, 9), 2)

    best = {'acc': -1, 'a1': None, 'a2': None, 'T': None}
    for a1_try in grid_a1:
        a2_try = 1.0 - a1_try
        sc = compute_score(train, a1_try, a2_try)
        for T_try in grid_T:
            pred = predict_label(sc, T_try)
            acc = np.mean(pred == train['true_label'])
            if acc > best['acc']:
                best = {'acc': acc, 'a1': a1_try, 'a2': a2_try, 'T': T_try}

    print(f"ğŸ” Best on Train: acc={best['acc']:.3f}, a1={best['a1']:.2f}, a2={best['a2']:.2f}, T={best['T']:.2f}")

    # ë² ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ë¡œ train/test ì˜ˆì¸¡ ì €ì¥
    train['score_best'] = compute_score(train, best['a1'], best['a2'])
    train['pred_best']  = predict_label(train['score_best'], best['T'])

    test['score_best'] = compute_score(test, best['a1'], best['a2'])
    test['pred_best']  = predict_label(test['score_best'], best['T'])

    out_train_best = os.path.join(OUT_DIR, "week2_train_best.csv")
    out_test_best  = os.path.join(OUT_DIR, "week2_test_best.csv")
    train[['id','score_best','pred_best']].to_csv(out_train_best, index=False)
    test[['id','score_best','pred_best']].to_csv(out_test_best, index=False)

    print("ğŸ’¾ Saved:", out_train_best)
    print("ğŸ’¾ Saved:", out_test_best)
else:
    print("â„¹ï¸ 'true_label' ì»¬ëŸ¼ì´ ì—†ì–´ Grid SearchëŠ” ìŠ¤í‚µí•©ë‹ˆë‹¤. (ì œì¶œ í›„ ê³µê°œ ê°€ì •)")
